{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split , validation_curve , cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "df = pd.read_csv(\"kc_house_data_modelisation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) #-- pour avoir tout le tableau dans sa largeur \n",
    "\n",
    "df = df.drop('Unnamed: 0',  axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop( [\"price\" ],axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['ratio chambre/salle de bain'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        300000.0\n",
       "1        647500.0\n",
       "2        400000.0\n",
       "3        235000.0\n",
       "4        402500.0\n",
       "           ...   \n",
       "20165    365000.0\n",
       "20166    380000.0\n",
       "20167    339000.0\n",
       "20168    399900.0\n",
       "20169    268950.0\n",
       "Name: price, Length: 20170, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.price\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.40, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsRegressor(n_neighbors=13)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor(n_neighbors=13)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knn =KNeighborsClassfiier()\n",
    "knn =KNeighborsRegressor(n_neighbors=13)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le score KNN arrondi à 2 décimales : 55.21 %\n"
     ]
    }
   ],
   "source": [
    "score = knn.score(X_test, y_test) * 100\n",
    "rounded_score = round(score, 2)\n",
    "print(\"le score KNN arrondi à 2 décimales :\", rounded_score, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.predict([[6,3.0,2400,2.0,0,0,0,1991,98002,2.0,1,0,0,\n",
    "          0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "          0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "          0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
    "]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# # Chargement des données dans un dataframe\n",
    "# df = pd.read_csv(\"kc_house_data_modelisation.csv\")\n",
    "\n",
    "# # Sélection des variables explicatives et de la variable cible (le prix)\n",
    "# X = df.drop(   [\"price\" ],  axis=1)\n",
    "\n",
    "# y = df['price']\n",
    "\n",
    "# # Création d'un objet régression linéaire et ajustement du modèle aux données\n",
    "# reg = LinearRegression()\n",
    "# reg.fit(X, y)\n",
    "\n",
    "# # Faire une prédiction sur de nouvelles données\n",
    "# X_new = [[6,3.0,2400,2.0,0,0,0,1991,2.0,1,0,0,\n",
    "#           0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "#           0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "#           0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
    "# ]]\n",
    "# y_new = reg.predict(X_new)\n",
    "\n",
    "# print(\"Prix prédit pour les nouvelles données :\", y_new, \"$\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le score LinearRegression arrondi à 5 décimales : 92.45505 %\n",
      "Prix prédit pour les nouvelles données : [379232.7756843] $\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\impej\\miniconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Chargement des données dans un dataframe\n",
    "df = pd.read_csv(\"kc_house_data_modelisation.csv\")\n",
    "\n",
    "# Sélection des variables explicatives et de la variable cible (le prix)\n",
    "X = df.drop(   ['Unnamed: 0',\"price\" ],  axis=1)\n",
    "\n",
    "y = df['price']\n",
    "\n",
    "# séparer les données en ensembles de formation et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "\n",
    "# ajuster le modèle de régression linéaire sur les données d'entraînement\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# calculer le score de prédiction\n",
    "score = lr.score(X_test, y_test)* 100\n",
    "rounded_score = round(score, 5)\n",
    "\n",
    "print(\"le score LinearRegression arrondi à 5 décimales :\", rounded_score, \"%\")\n",
    "\n",
    "# Création d'un objet régression linéaire et ajustement du modèle aux données\n",
    "reg = LinearRegression()\n",
    "reg.fit(X, y)\n",
    "\n",
    "# Faire une prédiction sur de nouvelles données\n",
    "X_new = [[6,3.0,2400,9373,2.0,0,0,7,0,1991,98002,47.3262,-122.214,2060,7316,\n",
    "          2.0,125.0,32.0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "          0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "          0,0,0,0,0,0,0,0,0,0\n",
    "\n",
    "]]\n",
    "y_new = reg.predict(X_new)\n",
    "\n",
    "print(\"Prix prédit pour les nouvelles données :\", y_new, \"$\")\n",
    "\n",
    "# le score LinearRegression arrondi à 5 décimales : 92.20186 %    --> si on supprime le 33 chambre et les 0 chambre \n",
    "# le score LinearRegression arrondi à 5 décimales : 92.45433 %   --> si on garde le 33 chambre et les 0 chambre \n",
    "# le score LinearRegression arrondi à 5 décimales : 92.45505 %   --> si on remplace les maison par celui qui a le max de chambre par la moyen de nombre de chambre \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# # Chargement des données dans un dataframe\n",
    "# df = pd.read_csv(\"kc_house_data_modelisation.csv\")\n",
    "\n",
    "# # Sélection des variables explicatives et de la variable cible (le prix)\n",
    "\n",
    "# X = df[[\"bedrooms\",\"bathrooms\",\"sqft_living\",\"sqft_lot\",\"floors\",\"waterfront\",\"view\",\"grade\",\"sqft_basement\",\"yr_renovated\",\"zipcode\",\n",
    "#          ]]  # \"price/sqft_living\"\n",
    "\n",
    "# y = df['price']\n",
    "\n",
    "# # séparer les données en ensembles de formation et de test\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "\n",
    "# # ajuster le modèle de régression linéaire sur les données d'entraînement\n",
    "# lr = LinearRegression()\n",
    "# lr.fit(X_train, y_train)\n",
    "\n",
    "# # calculer le score de prédiction\n",
    "# score = lr.score(X_test, y_test)* 100\n",
    "# rounded_score = round(score, 5)\n",
    "\n",
    "# print(\"le score LinearRegression arrondi à 5 décimales :\", rounded_score, \"%\")\n",
    "\n",
    "# # # Création d'un objet régression linéaire et ajustement du modèle aux données\n",
    "# # reg = LinearRegression()\n",
    "# # reg.fit(X, y)\n",
    "\n",
    "# # # Faire une prédiction sur de nouvelles données\n",
    "# # X_new = [[6,3.0,2400,9373,2.0,0,0,7,0,1991,98002,47.3262,-122.214\n",
    "\n",
    "# # ]]\n",
    "# # y_new = reg.predict(X_new)\n",
    "\n",
    "# # print(\"Prix prédit pour les nouvelles données :\", y_new, \"$\")\n",
    "\n",
    "\n",
    "# # 58.94501 %  \"price/sqft_living\"  --> sans les \"price/sqft_living\"\n",
    "\n",
    "# # le score LinearRegression arrondi à 5 décimales : 90.90134 %    --> si on supprime le 33 chambre et les 0 chambre \n",
    "# # le score LinearRegression arrondi à 5 décimales : 91.36943 %  --> si on garde le 33 chambre et les 0 chambre \n",
    "# # le score LinearRegression arrondi à 5 décimales : 91.37106 %   --> si on remplace les maison par celui qui a le max de chambre par la moyen de nombre de chambre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333328710441932"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#//////////////////////////////////         LinearRegression   /////////////////////////////////////////////////////\n",
    "#////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"kc_house_data_modelisation.csv\")\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "X = df[[\"bedrooms\",\"bathrooms\",\"sqft_living\",\"sqft_lot\",\"floors\",\"waterfront\",\"view\",\"grade\",\"sqft_basement\",\"yr_renovated\",\"zipcode\"\n",
    "       \t  ]] # \"bed_bath_ratio\",\t\"price/sqft_living\",\t\"price/sqft_lot\"\n",
    "y = df.price\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, random_state=42)\n",
    "\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = [\"zipcode\"] # est utilisée pour définir la liste des variables catégorielles dans l'ensemble de données\n",
    "\n",
    "\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "        # ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('min_max', MinMaxScaler()), \n",
    "        # ('scaler', RobustScaler()),\n",
    "        ])\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "categorical_transformer = OneHotEncoder(sparse_output=True)\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder ='passthrough'\n",
    ")\n",
    "\n",
    "\n",
    "#On obtient un pipeline de preprocessing qu'on peut utiliser dans un pipeline d'entainement\n",
    "\n",
    "lr = LinearRegression()\n",
    "pipe = Pipeline([\n",
    "     ('prep', preprocessor),\n",
    "     ('lr', lr)\n",
    "])\n",
    "trained_pipe = pipe.fit(X_train,y_train)\n",
    "trained_pipe.predict(X_test)\n",
    "trained_pipe.score(X_test,y_test)  \n",
    "\n",
    "# 0.84539752452148  avec ,\"view\",\"grade\" dans le categorical_features\n",
    "# 0.8404013922315632 \n",
    "# ('scaler', RobustScaler()),  0.8333308248004657\n",
    "# ('min_max', MinMaxScaler()), 0.8333328710441932\n",
    "# ridge = Ridge(alpha=1.0)     0.8328849301428648\n",
    "# lasso = Lasso(alpha=0.1)     0.8333321306063488"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333308248004657"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#//////////////////////////////////         RobustScaler   /////////////////////////////////////////////////////\n",
    "#////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"kc_house_data_modelisation.csv\")\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "X = df[[\"bedrooms\",\"bathrooms\",\"sqft_living\",\"sqft_lot\",\"floors\",\"waterfront\",\"view\",\"grade\",\"sqft_basement\",\"yr_renovated\",\"zipcode\"\n",
    "       \t  ]] # \"bed_bath_ratio\",\t\"price/sqft_living\",\t\"price/sqft_lot\"\n",
    "y = df.price\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, random_state=42)\n",
    "\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = [\"zipcode\"] # est utilisée pour définir la liste des variables catégorielles dans l'ensemble de données\n",
    "\n",
    "\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', RobustScaler()),\n",
    "        #('scaler', MinMaxScaler()), \n",
    "        ])\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "categorical_transformer = OneHotEncoder(sparse_output=True)\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder ='passthrough'\n",
    ")\n",
    "\n",
    "\n",
    "#On obtient un pipeline de preprocessing qu'on peut utiliser dans un pipeline d'entainement\n",
    "\n",
    "lr = LinearRegression()\n",
    "# ridge = Ridge(alpha=1.0)\n",
    "# lasso = Lasso(alpha=0.1)\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "     ('prep', preprocessor),\n",
    "     ('lr', lr),\n",
    "    #  ('ridge', ridge),\n",
    "    # ('lasso', lasso)\n",
    "])\n",
    "trained_pipe = pipe.fit(X_train,y_train)\n",
    "trained_pipe.predict(X_test)\n",
    "trained_pipe.score(X_test,y_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score R² pour le modèle Ridge : 0.8328849301\n"
     ]
    }
   ],
   "source": [
    "#////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#//////////////////////////////////         Ridge   /////////////////////////////////////////////////////\n",
    "#////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Chargement des données\n",
    "df = pd.read_csv(\"kc_house_data_modelisation.csv\")\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Séparation des variables explicatives et de la variable cible\n",
    "X = df[[\"bedrooms\",\"bathrooms\",\"sqft_living\",\"sqft_lot\",\"floors\",\"waterfront\",\"view\",\"grade\",\"sqft_basement\",\"yr_renovated\",\"zipcode\"]] \n",
    "y = df.price\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, random_state=42)\n",
    "\n",
    "# Sélection des colonnes numériques et catégorielles\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = [\"zipcode\"] \n",
    "\n",
    "# Création des transformateurs pour les données numériques et catégorielles\n",
    "numeric_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', MinMaxScaler()), \n",
    "])\n",
    "\n",
    "categorical_transformer = OneHotEncoder(sparse_output=True)\n",
    "\n",
    "# Création du preprocesseur avec les transformateurs pour les données numériques et catégorielles\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder ='passthrough'\n",
    ")\n",
    "\n",
    "# Création du pipeline avec le preprocesseur et le modèle Ridge\n",
    "ridge = Ridge(alpha=1.0)\n",
    "pipe = Pipeline([\n",
    "     ('prep', preprocessor),\n",
    "     ('ridge', ridge)\n",
    "])\n",
    "\n",
    "# Entraînement du modèle\n",
    "trained_pipe = pipe.fit(X_train,y_train)\n",
    "\n",
    "# Prédiction sur l'ensemble de test et calcul du score R²\n",
    "score = trained_pipe.score(X_test,y_test)\n",
    "print(\"Score R² pour le modèle Ridge : {:.10f}\".format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score of Lasso:  0.8423086998977523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\impej\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:592: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5330101238626.141, tolerance: 97466042998.38896\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "#////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#//////////////////////////////////         Lasso   /////////////////////////////////////////////////////\n",
    "#////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Chargement des données\n",
    "df = pd.read_csv(\"kc_house_data_modelisation.csv\")\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Séparation des variables explicatives et de la variable cible\n",
    "X = df[[\"bedrooms\", \"bathrooms\", \"sqft_living\", \"sqft_lot\", \"floors\", \"waterfront\", \"view\", \"grade\", \"sqft_basement\", \"yr_renovated\", \"zipcode\"]]\n",
    "y = df.price\n",
    "\n",
    "# Division des données en ensembles d'apprentissage et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, random_state=42)\n",
    "\n",
    "# Définition des transformateurs pour les variables numériques et catégorielles\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(sparse_output=True))])\n",
    "\n",
    "# Définition de la transformation des variables explicatives\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, [\"bedrooms\", \"bathrooms\", \"sqft_living\", \"sqft_lot\", \"floors\", \"waterfront\", \"view\", \"grade\", \"sqft_basement\", \"yr_renovated\"]),\n",
    "        ('cat', categorical_transformer, [\"zipcode\"])])\n",
    "\n",
    "# Définition du modèle de régression Lasso\n",
    "lasso = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('lasso', Lasso(alpha=0.1))])\n",
    "\n",
    "# Entraînement du modèle de régression Lasso\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Évaluation du modèle de régression Lasso sur l'ensemble de test\n",
    "y_pred = lasso.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2 score of Lasso: \", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333326722547137"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#//////////////////////////////////         StandardScaler   /////////////////////////////////////////////////////\n",
    "#////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df = pd.read_csv(\"kc_house_data_modelisation.csv\")\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "X = df[[\"bedrooms\",\"bathrooms\",\"sqft_living\",\"sqft_lot\",\"floors\",\"waterfront\",\"view\",\"grade\",\"sqft_basement\",\"yr_renovated\",\"zipcode\"\n",
    "       \t  ]]\n",
    "y = df.price\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, random_state=42)\n",
    "\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = [\"zipcode\"]\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "categorical_transformer = OneHotEncoder(sparse_output=True)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder ='passthrough'\n",
    ")\n",
    "\n",
    "lr = LinearRegression()\n",
    "pipe = Pipeline([\n",
    "     ('prep', preprocessor),\n",
    "     ('lr', lr)\n",
    "])\n",
    "trained_pipe = pipe.fit(X_train,y_train)\n",
    "trained_pipe.predict(X_test)\n",
    "trained_pipe.score(X_test,y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b3256ad06983c34c3d35f0046b7ca12c3677676962e1bf5e104a75bd281eed85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
